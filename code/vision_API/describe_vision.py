from google.cloud import vision
from google.api_core import exceptions as g_exceptions
from google.auth.exceptions import TransportError

import io
import json
import os
import time


# ========= 1. åˆå§‹åŒ– Vision API =========
client = vision.ImageAnnotatorClient.from_service_account_file(
    "C:\\Users\\stchang\\OneDrive\\æ–‡ä»¶\\Social_Media_Analysis\\socialmediaanalysis-477306-502b5950f40c.json"
)


# ========= 2. ç¶²è·¯éŒ¯èª¤é‡è©¦å‡½å¼ =========
def annotate_with_retry(client, image, features, max_backoff: int = 300):
    """
    Vision API å‘¼å«å¤±æ•—ï¼ˆç¶²è·¯/503/timeoutï¼‰æ™‚ç„¡é™é‡è©¦ã€‚
    max_backoffï¼šæŒ‡æ•¸é€€é¿æœ€å¤§ç­‰å¾…ç§’æ•¸ã€‚
    """
    backoff = 5
    while True:
        try:
            return client.annotate_image({'image': image, 'features': features})

        except (
            g_exceptions.ServiceUnavailable,
            g_exceptions.DeadlineExceeded,
            g_exceptions.Unknown,
            g_exceptions.InternalServerError,
            TransportError,
        ) as e:
            print(f"[WARN] API æš«æ™‚éŒ¯èª¤ï¼š{e}")
            print(f"       {backoff} ç§’å¾Œé‡è©¦ï¼ŒåŒä¸€å¼µåœ–ç‰‡ä¸æœƒè¢«è·³é...")
            time.sleep(backoff)
            backoff = min(backoff * 2, max_backoff)

        except Exception as e:
            print(f"[ERROR] éç¶²è·¯ç›¸é—œéŒ¯èª¤ï¼š{e}")
            raise



# ========= 3. å®šç¾©åµæ¸¬ features =========
features = [
    vision.Feature(type_=vision.Feature.Type.TEXT_DETECTION), # æ–‡å­—åµæ¸¬ (æª¢æ¸¬åœ–åƒä¸­çš„æ–‡å­—ï¼Œé€šå¸¸ç”¨æ–¼ç°¡çŸ­æ–‡å­—)
    vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION), # æ–‡ä»¶æ–‡å­—åµæ¸¬ (å°ˆç‚ºæ–‡ä»¶è¨­è¨ˆï¼Œæä¾›æ›´è©³ç´°çš„æ–‡å­—çµæ§‹è³‡è¨Š)
    vision.Feature(type_=vision.Feature.Type.LANDMARK_DETECTION), # åœ°æ¨™åµæ¸¬ (æª¢æ¸¬åœ–åƒä¸­çš„è‘—ååœ°æ¨™)
    vision.Feature(type_=vision.Feature.Type.LOGO_DETECTION), # å•†æ¨™åµæ¸¬ (æª¢æ¸¬åœ–åƒä¸­çš„å•†æ¨™)
    vision.Feature(type_=vision.Feature.Type.LABEL_DETECTION), # æ¨™ç±¤åµæ¸¬ (æª¢æ¸¬åœ–åƒçš„é€šç”¨æ¨™ç±¤æˆ–åˆ†é¡)
    vision.Feature(type_=vision.Feature.Type.IMAGE_PROPERTIES), # åœ–ç‰‡å±¬æ€§åµæ¸¬ (æª¢æ¸¬åœ–ç‰‡çš„å±¬æ€§ï¼Œå¦‚ä¸»è‰²èª¿)
    vision.Feature(type_=vision.Feature.Type.OBJECT_LOCALIZATION), # ç‰©ä»¶åµæ¸¬ (æª¢æ¸¬ä¸¦å®šä½åœ–åƒä¸­çš„ç‰¹å®šç‰©ä»¶åŠå…¶é‚Šç•Œæ¡†)
    vision.Feature(type_=vision.Feature.Type.CROP_HINTS), # è£åˆ‡å»ºè­° (æä¾›æœ€ä½³çš„åœ–ç‰‡è£åˆ‡å»ºè­°åŠå…¶é‚Šç•Œæ¡†å’Œä¿¡å¿ƒåˆ†æ•¸)
    vision.Feature(type_=vision.Feature.Type.WEB_DETECTION), # ç¶²è·¯åµæ¸¬ (åœ¨ç¶²è·¯ä¸Šå°‹æ‰¾èˆ‡åœ–åƒç›¸é—œçš„è³‡è¨Šï¼Œå¦‚åŒ¹é…åœ–ç‰‡å’Œå¯¦é«”)
    vision.Feature(type_=vision.Feature.Type.SAFE_SEARCH_DETECTION), # å®‰å…¨æœå°‹åµæ¸¬ (è©•ä¼°åœ–åƒæ˜¯å¦åŒ…å«ä¸å®‰å…¨å…§å®¹ï¼Œå¦‚æˆäººã€æš´åŠ›ç­‰)
    vision.Feature(type_=vision.Feature.Type.FACE_DETECTION) # è‡‰éƒ¨åµæ¸¬ (æª¢æ¸¬åœ–åƒä¸­çš„è‡‰éƒ¨ã€æƒ…ç·’ã€åœ°æ¨™ç­‰)
]


# ========= 4. éæ­· vision_data å…§æ‰€æœ‰å­è³‡æ–™å¤¾ =========
root_folder = "C:\\Users\\stchang\\OneDrive\\æ–‡ä»¶\\Social_Media_Analysis\\data\\vision_data"

for dirpath, dirnames, filenames in os.walk(root_folder):

    if dirpath == root_folder:
        continue  # è·³é rootï¼ˆåªè™•ç†å­è³‡æ–™å¤¾ï¼‰

    output_folder = os.path.join(dirpath, "vision_description")
    os.makedirs(output_folder, exist_ok=True)

    print(f"\n=== è™•ç†è³‡æ–™å¤¾ï¼š{dirpath} ===")
    print(f"è¼¸å‡ºä½ç½®ï¼š{output_folder}")

    for filename in filenames:

        # åªè™•ç†åœ–ç‰‡æ ¼å¼
        if not filename.lower().endswith((".jpg", ".jpeg", ".png", ".bmp", ".webp")):
            continue

        image_path = os.path.join(dirpath, filename)

        # ====== âœ” æª¢æŸ¥æ˜¯å¦å·²è™•ç† ======
        output_json_name = os.path.splitext(filename)[0] + "_vision_results.json"
        output_json_path = os.path.join(output_folder, output_json_name)

        if os.path.exists(output_json_path):
            print(f"âœ” å·²è™•ç†ï¼Œè·³éï¼š{filename}")
            continue

        # ====== â†˜ æœªè™•ç† â†’ é–‹å§‹åˆ†æ ======
        print(f"\nâ¡ è™•ç†åœ–ç‰‡ï¼š{filename}")

        try:
            with io.open(image_path, 'rb') as f:
                content = f.read()

            image = vision.Image(content=content)

            # ğŸ”¥ ä½¿ç”¨é‡è©¦åŒ…è£çš„ API
            response = annotate_with_retry(client, image, features)

            # ======= ä½ åŸæœ¬è¶…å®Œæ•´çš„è§£æé‚è¼¯ =======
            # ï¼ˆé€™æ®µä¿ç•™ä½ è‡ªå·±çš„ï¼Œä¸æ”¹å‹•ï¼‰
            results_dict = {} # åˆå§‹åŒ–ä¸€å€‹ç©ºå­—å…¸ä¾†å„²å­˜çµæœ
            results_dict['image_name'] = filename # å°‡åœ–ç‰‡åŸå§‹æª”ååŠ å…¥å­—å…¸

            # æ ¹æ“š features åˆ—è¡¨ä¸­å®šç¾©çš„é †åºï¼Œé€ä¸€è™•ç†ä¸¦å°‡çµæœæ·»åŠ åˆ° results_dict ä¸­
            for feature in features:
                if feature.type_ == vision.Feature.Type.TEXT_DETECTION:
                    # è™•ç†æ–‡å­—åµæ¸¬çµæœ
                    if response.text_annotations:
                        # text_annotations åˆ—è¡¨ä¸­çš„ç¬¬ä¸€å€‹é …ç›®é€šå¸¸æ˜¯æ•´å€‹åœ–åƒçš„æ–‡å­—
                        # æˆ‘å€‘å°‡æ¯å€‹åµæ¸¬åˆ°çš„æ–‡å­—å€å¡Šçš„è©³ç´°è³‡è¨Š (description, bounding box, score) åŠ å…¥åˆ—è¡¨
                        results_dict['text_annotations'] = []
                        for text in response.text_annotations:
                            vertices = []
                            if text.bounding_poly: # Check if bounding_poly exists
                                for vertex in text.bounding_poly.vertices:
                                    vertices.append({'x': vertex.x, 'y': vertex.y})
                            results_dict['text_annotations'].append({
                                'description': text.description,
                                'bounding_poly': {'vertices': vertices},
                                'score': text.score if hasattr(text, 'score') else 0.0 # Include score if available (not always for text detection), default to 0.0 if none
                            })
                    else:
                        results_dict['text_annotations'] = "No text detected."
                elif feature.type_ == vision.Feature.Type.DOCUMENT_TEXT_DETECTION:
                    # è™•ç†æ–‡ä»¶æ–‡å­—åµæ¸¬çµæœ
                    if response.full_text_annotation:
                        # full_text_annotation åŒ…å«æ–‡ä»¶ä¸­çš„å®Œæ•´æ–‡å­—å…§å®¹åŠæ›´è©³ç´°çš„çµæ§‹è³‡è¨Š
                        document_info = {
                            'text': response.full_text_annotation.text,
                            'pages': []
                        }
                        for page in response.full_text_annotation.pages:
                            page_info = {
                                'property': {
                                    'detected_languages': [{'language_code': lang.language_code, 'confidence': lang.confidence} for lang in page.property.detected_languages] if page.property and page.property.detected_languages else [],
                                },
                                'width': page.width,
                                'height': page.height,
                                'blocks': []
                            }
                            for block in page.blocks:
                                block_info = {
                                    'property': {
                                        'detected_languages': [{'language_code': lang.language_code, 'confidence': lang.confidence} for lang in block.property.detected_languages] if block.property and block.property.detected_languages else [],
                                        'detected_break': {'type': block.property.detected_break.type_.name, 'is_prefix': block.property.detected_break.is_prefix} if block.property and block.property.detected_break else None
                                    },
                                    'bounding_box': [{'x': vertex.x, 'y': vertex.y} for vertex in block.bounding_box.vertices],
                                    'paragraphs': [],
                                    'block_type': block.block_type.name,
                                    'confidence': block.confidence
                                }
                                for paragraph in block.paragraphs:
                                    paragraph_info = {
                                        'property': {
                                            'detected_languages': [{'language_code': lang.language_code, 'confidence': lang.confidence} for lang in paragraph.property.detected_languages] if paragraph.property and paragraph.property.detected_languages else [],
                                            'detected_break': {'type': paragraph.property.detected_break.type_.name, 'is_prefix': paragraph.property.detected_break.is_prefix} if paragraph.property and paragraph.property.detected_break else None
                                        },
                                        'bounding_box': [{'x': vertex.x, 'y': vertex.y} for vertex in paragraph.bounding_box.vertices],
                                        'words': [],
                                        'confidence': paragraph.confidence
                                    }
                                    for word in paragraph.words:
                                        word_info = {
                                            'property': {
                                                'detected_languages': [{'language_code': lang.language_code, 'confidence': lang.confidence} for lang in word.property.detected_languages] if word.property and word.property.detected_languages else [],
                                                'detected_break': {'type': word.property.detected_break.type_.name, 'is_prefix': word.property.detected_break.is_prefix} if word.property and word.property.detected_break else None
                                            },
                                            'bounding_box': [{'x': vertex.x, 'y': vertex.y} for vertex in word.bounding_box.vertices],
                                            'symbols': [{'property': {'detected_languages': [{'language_code': lang.language_code, 'confidence': lang.confidence} for lang in symbol.property.detected_languages] if symbol.property and symbol.property.detected_languages else [], 'detected_break': {'type': symbol.property.detected_break.type_.name, 'is_prefix': symbol.property.detected_break.is_prefix} if symbol.property and symbol.property.detected_break else None}, 'bounding_box': [{'x': vertex.x, 'y': vertex.y} for vertex in symbol.bounding_box.vertices], 'text': symbol.text, 'confidence': symbol.confidence} for symbol in word.symbols],
                                            'confidence': word.confidence
                                        }
                                        paragraph_info['words'].append(word_info)
                                    block_info['paragraphs'].append(paragraph_info)
                                page_info['blocks'].append(block_info)
                            document_info['pages'].append(page_info)
                        results_dict['document_text_annotation'] = document_info
                    else:
                        results_dict['document_text_annotation'] = "No document text detected."
                elif feature.type_ == vision.Feature.Type.LANDMARK_DETECTION:
                    # è™•ç†åœ°æ¨™åµæ¸¬çµæœ
                    if response.landmark_annotations:
                        # éæ­·æ¯å€‹åµæ¸¬åˆ°çš„åœ°æ¨™ï¼Œæå–æè¿°ã€åˆ†æ•¸å’Œä½ç½®è³‡è¨Š
                        results_dict['landmarks'] = []
                        for landmark in response.landmark_annotations:
                            locations = []
                            if landmark.locations:
                                for loc in landmark.locations:
                                    lat_lng = loc.lat_lng
                                    locations.append({'latitude': lat_lng.latitude, 'longitude': lat_lng.longitude})
                            results_dict['landmarks'].append({
                                'description': landmark.description,
                                'score': landmark.score,
                                'locations': locations,
                                'bounding_poly': [{'x': vertex.x, 'y': vertex.y} for vertex in landmark.bounding_poly.vertices] if landmark.bounding_poly else []
                            })
                    else:
                        results_dict['landmarks'] = "No landmarks detected."
                elif feature.type_ == vision.Feature.Type.LOGO_DETECTION:
                    # è™•ç†å•†æ¨™åµæ¸¬çµæœ
                    if response.logo_annotations:
                        # éæ­·æ¯å€‹åµæ¸¬åˆ°çš„å•†æ¨™ï¼Œæå–æè¿°ã€åˆ†æ•¸å’Œé‚Šç•Œæ¡†
                        results_dict['logos'] = []
                        for logo in response.logo_annotations:
                            results_dict['logos'].append({
                                'description': logo.description,
                                'score': logo.score,
                                'bounding_poly': [{'x': vertex.x, 'y': vertex.y} for vertex in logo.bounding_poly.vertices] if logo.bounding_poly else []
                            })
                    else:
                        results_dict['logos'] = "No logos detected."
                elif feature.type_ == vision.Feature.Type.LABEL_DETECTION:
                    # è™•ç†æ¨™ç±¤åµæ¸¬çµæœ (é€šç”¨æ¨™ç±¤)
                    if response.label_annotations:
                        # éæ­·æ¯å€‹åµæ¸¬åˆ°çš„æ¨™ç±¤ï¼Œæå–æè¿°å’Œåˆ†æ•¸
                        results_dict['labels'] = [{'description': label.description, 'score': label.score} for label in response.label_annotations]
                    else:
                        results_dict['labels'] = "No labels detected."
                elif feature.type_ == vision.Feature.Type.IMAGE_PROPERTIES:
                    # è™•ç†åœ–ç‰‡å±¬æ€§åµæ¸¬çµæœ (ä¸»è‰²èª¿)
                    if response.image_properties_annotation:
                        props = response.image_properties_annotation.dominant_colors
                        if props and props.colors:
                            results_dict['image_properties'] = {'dominant_colors': []}
                            # éæ­·æ¯å€‹ä¸»è‰²èª¿ï¼Œæå–é¡è‰² (RGB å’Œ Alpha) å’Œåˆ†æ•¸
                            for color_info in props.colors:
                                color = color_info.color

                                # ğŸ”¸ æŠŠ FloatValue è½‰æˆä¸€èˆ¬çš„ floatï¼ˆæˆ– Noneï¼‰
                                alpha_raw = getattr(color, "alpha", None)
                                if hasattr(alpha_raw, "value"):       # FloatValue ç‰©ä»¶
                                    alpha_value = float(alpha_raw.value)
                                else:
                                    # å¯èƒ½æ˜¯ floatã€0 æˆ– None
                                    alpha_value = float(alpha_raw) if alpha_raw is not None else None

                                results_dict['image_properties']['dominant_colors'].append({
                                    'color': {
                                        'red': color.red,
                                        'green': color.green,
                                        'blue': color.blue,
                                        'alpha': alpha_value,
                                    },
                                    'score': color_info.score,
                                    'pixel_fraction': color_info.pixel_fraction
                                })
                        else:
                            results_dict['image_properties'] = "No dominant colors detected."
                    else:
                        results_dict['image_properties'] = "No image properties detected."

                elif feature.type_ == vision.Feature.Type.OBJECT_LOCALIZATION:
                    # è™•ç†ç‰©ä»¶åµæ¸¬çµæœ (åŒ…æ‹¬é‚Šç•Œæ¡†)
                    if response.localized_object_annotations:
                        results_dict['object_localizations'] = []
                        # éæ­·æ¯å€‹åµæ¸¬åˆ°çš„ç‰©ä»¶ï¼Œæå–åç¨±ã€åˆ†æ•¸å’Œé‚Šç•Œæ¡†çš„æ¨™æº–åŒ–åº§æ¨™
                        for obj in response.localized_object_annotations:
                            vertices = []
                            for vertex in obj.bounding_poly.normalized_vertices:
                                vertices.append({'x': vertex.x, 'y': vertex.y})
                            results_dict['object_localizations'].append({
                                'name': obj.name,
                                'score': obj.score,
                                'bounding_poly': {'normalized_vertices': vertices}
                            })
                    else:
                        results_dict['object_localizations'] = "No objects detected."
                elif feature.type_ == vision.Feature.Type.CROP_HINTS:
                    # è™•ç†è£åˆ‡å»ºè­° (åŒ…æ‹¬é‚Šç•Œæ¡†å’Œä¿¡å¿ƒåˆ†æ•¸)
                    if response.crop_hints_annotation and response.crop_hints_annotation.crop_hints:
                        results_dict['crop_hints'] = []
                        # éæ­·æ¯å€‹è£åˆ‡å»ºè­°ï¼Œæå–é‚Šç•Œæ¡†çš„åƒç´ åº§æ¨™å’Œä¿¡å¿ƒåˆ†æ•¸
                        for crop_hint in response.crop_hints_annotation.crop_hints:
                            vertices = []
                            for vertex in crop_hint.bounding_poly.vertices:
                                vertices.append({'x': vertex.x, 'y': vertex.y})
                            results_dict['crop_hints'].append({
                                'bounding_poly': {'vertices': vertices},
                                'confidence': crop_hint.confidence # è£åˆ‡å»ºè­°çš„ä¿¡å¿ƒåˆ†æ•¸
                            })
                    else:
                        results_dict['crop_hints'] = "No crop hints detected."
                elif feature.type_ == vision.Feature.Type.WEB_DETECTION:
                    # è™•ç†ç¶²è·¯åµæ¸¬çµæœ
                    if response.web_detection:
                        web_info = {}
                        # æå–ç¶²è·¯å¯¦é«”
                        if response.web_detection.web_entities:
                            web_info['web_entities'] = [{'description': entity.description, 'score': entity.score} for entity in response.web_detection.web_entities]
                        # æå–å®Œæ•´åŒ¹é…åœ–ç‰‡
                        if response.web_detection.full_matching_images:
                            web_info['full_matching_images'] = [{'url': image.url} for image in response.web_detection.full_matching_images]
                        # æå–éƒ¨åˆ†åŒ¹é…åœ–ç‰‡
                        if response.web_detection.partial_matching_images:
                            web_info['partial_matching_images'] = [{'url': image.url} for image in response.web_detection.partial_matching_images]
                        # æå–è¦–è¦ºç›¸ä¼¼åœ–ç‰‡
                        if response.web_detection.visually_similar_images:
                            web_info['visually_similar_images'] = [{'url': image.url} for image in response.web_detection.visually_similar_images]
                        # æå–åŒ…å«åŒ¹é…åœ–ç‰‡çš„ç¶²é 
                        if response.web_detection.pages_with_matching_images:
                            web_info['pages_with_matching_images'] = [{'url': page.url} for page in response.web_detection.pages_with_matching_images]
                        # æå–æœ€ä½³çŒœæ¸¬æ¨™ç±¤
                        if response.web_detection.best_guess_labels:
                            web_info['best_guess_labels'] = [{'label': label.label, 'language_code': label.language_code} for label in response.web_detection.best_guess_labels]

                        if web_info:
                            results_dict['web_detection'] = web_info
                        else:
                            results_dict['web_detection'] = "No web detection results."
                    else:
                        results_dict['web_detection'] = "No web detection results."

                elif feature.type_ == vision.Feature.Type.SAFE_SEARCH_DETECTION:
                    # è™•ç†å®‰å…¨æœå°‹åµæ¸¬çµæœ
                    if response.safe_search_annotation:
                        safe = response.safe_search_annotation
                        # å°‡å„é …å®‰å…¨è©•ä¼°çµæœ (enum) è½‰æ›ç‚ºå…¶åç¨±å­—ä¸²
                        results_dict['safe_search_properties'] = {
                            'adult': safe.adult.name,
                            'spoof': safe.spoof.name,
                            'medical': safe.medical.name,
                            'violence': safe.violence.name,
                            'racy': safe.racy.name
                        }
                    else:
                        results_dict['safe_search_properties'] = "No safe search properties detected."
                elif feature.type_ == vision.Feature.Type.FACE_DETECTION:
                    # è™•ç†è‡‰éƒ¨åµæ¸¬çµæœ
                    if response.face_annotations:
                        results_dict['faces'] = []
                        for face in response.face_annotations:
                            # å…ˆé¸ç”¨ fd_bounding_polyï¼Œè‹¥æ²’æœ‰å‰‡é€€å› bounding_poly
                            box_vertices = []
                            poly = None
                            if getattr(face, "fd_bounding_poly", None) and face.fd_bounding_poly.vertices:
                                poly = face.fd_bounding_poly
                            elif getattr(face, "bounding_poly", None) and face.bounding_poly.vertices:
                                poly = face.bounding_poly

                            if poly is not None:
                                for vertex in poly.vertices:
                                    box_vertices.append({"x": vertex.x, "y": vertex.y})

                            face_info = {
                                "detection_confidence": face.detection_confidence,
                                "joy_likelihood": face.joy_likelihood.name,
                                "sorrow_likelihood": face.sorrow_likelihood.name,
                                "anger_likelihood": face.anger_likelihood.name,
                                "surprise_likelihood": face.surprise_likelihood.name,
                                "under_exposed_likelihood": face.under_exposed_likelihood.name,
                                "blurred_likelihood": face.blurred_likelihood.name,
                                "headwear_likelihood": face.headwear_likelihood.name,
                                "detection_bounding_box": box_vertices,
                                "landmarks": [
                                    {
                                        "type": landmark.type_.name,
                                        "position": {
                                            "x": landmark.position.x,
                                            "y": landmark.position.y,
                                            "z": landmark.position.z,
                                        },
                                    }
                                    for landmark in (face.landmarks or [])
                                ] if face.landmarks else "No landmarks",
                            }
                            results_dict["faces"].append(face_info)
                    else:
                        results_dict["faces"] = "No faces detected."

            # ================================


            # è¼¸å‡º JSON
            output_filename = os.path.splitext(filename)[0] + "_vision_results.json"
            output_path = os.path.join(output_folder, output_filename)

            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(results_dict, f, ensure_ascii=False, indent=4)

            print(f"âœ” åµæ¸¬å®Œæˆ â†’ {output_path}")

        except Exception as e:
            print(f"[ERROR] è™•ç†å¤±æ•—ï¼ˆä¸è·³éï¼Œè«‹ä¿®æ­£å•é¡Œï¼‰ï¼š{e}")
            raise  # åœä¸‹ä¾†è®“ä½ çœ‹éŒ¯èª¤ï¼ˆé¿å…è·³éåœ–ç‰‡ï¼‰
